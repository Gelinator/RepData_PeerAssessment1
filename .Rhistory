res
?separate
separate(res,sex_class, into = c("sex", "class"))
submit()
submit()
students3
submit()
submit()
?spread
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
students4
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed,status == "passed")
play()
?mutate
passed <- mutate(passed, status = status =="passed")
passed <- mutate(passed, status = "passed")
nxt()
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed, failed)
sat
submit()
play()
?separate
nxt()
submit()
submit()
submit()
submit()
?read.xml
?xmParse
?xmlParse
library(XML)
?xmlParse
data <- xmlParse(http://laws-lois.justice.gc.ca/eng/XML/I-11.8.xml)
data <- xmlParse("http://laws-lois.justice.gc.ca/eng/XML/I-11.8.xml")
view(data)
View(data)
data
xmlTreeParse(data)
install.packages("knitr")
library(knitr)
?knitr
library(UsingR)
load("/Volumes/FILES/MOOCs/Data Science/Practice stuff/World Bank stuff/LoadedSet.RData")
library(tidyr)
?tidyr
load("~/Desktop/Mi biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
a
View(car)
carType <- car
rm(car)
View(bump)
load("~/Desktop/Mi biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
library(swirl)
install_from_swirl("Regression Models")
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent, galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
quit
quit()
data(mtcars)
mtcars
plot(mtcars$am,mtcars$mpg)
cor(mtcars$am,mtcars$mpg)
?lm
cars <- lm(mtcars$mpg, mtcars$am)
cars <- lm(mtcars$mpg ~ mtcars$am)
summary cars
summary(cars)
library(swirl)
swirl()
install_from_swirl("Statistical Inference")
swirl()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
?gather
res<-gather(students2,sex_class,count)
res <- gather(students2,sex_class,count)
res <- gather(students2,sex_class,count,-grade)
rest
res
?separate
separate(res,sex_class, c("sex","class"))
submit()
students3
submit()
?spread
submit()
submit()
submit()
submit()
extract_numeric("class5")
reset()
submit()
submit()
submit()
submit()
submit()
submit()
?mutate
submit()
students4
submit()
submit()
submit()
submit()
passed
failed
passed <- mutate(passed,status == "passed")
passed <- mutate(passed,status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed, failed)
sat
submit()
submit()
submit()
submit()
submit()
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
temp$X * temp$Prob
temp
hd <- c(-4*.2,.8
)
var(hd)
?var
var(temp)
mean(temp)
temp(x)
temp(X)
temp[X]
temp[,1]
temp[1,]
temp[1,]*temp[,1]
mean(temp[1,]*temp[,1])
p <- c(.1, .2, .3, .4)
x <- 2 : 5
p*x
var(p*x)
sqrt(p^2*x)
sqrt(sum(p^2*x))
sum(p^2*x)
sum(x ^ 2 * p) - sum(x * p) ^ 2
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
sum(temp)
sum(temp[,1:4])
sum(temp[,1:4]*temp[1:4,])
sum(temp[,1:4]*temp[1:2,])
x*p
sum(x*p)
class(temp)
?matrix
levles(temp)
levels(temp)
dimnames(temp)
dim(temp)
dim<-(temp)
rm(dim)
X
temp(X)
temp[X]
library(swirl)
swirl()
1-((2+1)/36)
deck
52
1/13
0
3/13
2/51
library(readxl)
install.packages("readxl")
install.packages("rvest")
vignette("selectorgadget")
library(ggplot2)
?mean
load("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
class(bump$Date)
class(bump$Time)
?plot
?ddply
library(plyr)
?ddply
?Date
unique(years(bump$Date)
)
unique(year(bump$Date))
year(today())
today()
year(Sys.Date())
Sys.Date()
months(Sys.Date())
load("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
bump$Year <- strftime(bump$Date,format = "%Y")
hist(bump$Year)
?hist
hist(as.numeric(bump$Year))
unique(bump$Year)
qplot(bump$Number_of_Casualties,bump$Date)
library(ggplot2)
qplot(bump$Number_of_Casualties,bump$Date)
qplot(bump$Number_of_Casualties,bump$Date, geom = "jitter")
large <- bump[bump$Number_of_Casualties > 25]
large <- bump[,bump$Number_of_Casualties > 25]
large <- subset(bump,bump$Number_of_Casualties > 25)
View(large)
View(Rurality)
hist(large$Urban_or_Rural)
qplot(large$Urban_or_Rural, geom="histogram")
qplot(large$Urban_or_Rural, geom="density")
qplot(large$Urban_or_Rural, geom="smooth")
qplot(large$Weather_Conditions,large$Urban_or_Rural, geom="smooth")
qplot(large$Weather_Conditions,large$Urban_or_Rural)
qplot(large$Urban_or_Rural,large$Weather_Conditions)
qplot(large$Urban_or_Rural,large$Weather_Conditions, geom="smooth")
qplot(large$Urban_or_Rural,large$Weather_Conditions, geom="boxplot")
qplot(large$Urban_or_Rural,large$Weather_Conditions, geom="line")
qplot(large$Urban_or_Rural,large$Weather_Conditions)
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large?)
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large$Speed_limit)
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large$Speed_limit,geom="histogram")
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large$Speed_limit,geom="density")
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large$Speed_limit)
qplot(large$Urban_or_Rural,large$Weather_Conditions, colour=large$Speed_limit, geom="jitter")
save.image("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
qplot(large$Urban_or_Rural,large$Number_of_Casualties, colour=large$Speed_limit, geom="jitter")
qplot(large$Speed_limit,large$Number_of_Casualties, colour=large$Urban_or_Rural, geom="jitter")
load("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
cor(large$Urban_or_Rural,large$Number_of_Casualties)
cor(large$Speed_limit,large$Number_of_Casualties)
as.numeric(large$Year)
hist(as.numeric(bump$Year))
names(car)
?merge
fullout <- merge(bump,car,by.x="Accident_Index", by.y="Acc_Index")
summary(fullout)
save.image("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro LARGE.RData")
load("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro LARGE.RData")
fullout <- merge(fullout,mort,by.x="Accident_Index",by.y="Acc_Index")
casualty <- names(mort)
rm(mort)
rm(a,b,c)
carData <- names(car)
rm(car)
accData <- names(bump)
rm(bump)
str(fullout)
View(fullout)
save.image("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents all data.RData")
load("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents enviro.RData")
rename(bump,"Accident_Index"="Acc_Index")
library(plyr)
rename(bump,"Accident_Index"="Acc_Index")
rename(bump,"Accident_Index"=="Acc_Index")
rename(bump,c("Accident_Index"="Acc_Index"))
rename(bump,c("Accident_Index"="Acc_Index"))
names(bump)[0] <- "Acc_Index"
names(bump)[0]
names(bump)[1]
names(bump)[1] <- "Acc_Index"
a
b
c
merge(car,mort)
dataset <- merge(car,mort)
dataset <- merge(dataset,bump)
rm(car,bump,mort)
accLabels <- c
rm(c)
carLabels <- a
rm(a)
casualtyLabels <- b
rm(b)
save.image("~/Documents/Biz/Insurance/Stats19-Data2005-2013/UK Accidents all data.RData")
load("~/Documents/Biz/Insurance/Simulations/Max10k Pools.RData")
View(results)
qplot(abs(results$Spread.Perc),results$n,colour=results$Std.Perc)
library(ggplot2)
qplot(abs(results$Spread.Perc),results$n,colour=results$Std.Perc)
qplot(abs(results$Spread.Perc),results$n)
?write.csv
write.csv(results, "Results 10k.csv")
library(rvest)
?rvest
library(rvest)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
class(lego_movie)
rm(lego_movie)
install.packages("neural")
library(neural)
?neural
age <- c(16:45)
-3E-07*age^4 + 4E-05*age^3 - 0.0014*age^2 + 0.0163*age + 0.0492
-3E
-3E-07
-3*10^-7*age^4 + 4*10^-5*age^3 - 0.0014*age^2 + 0.0163*age + 0.0492
age <- c(16:45)
freq <- -3*10^-7*age^4 + 4*10^-5*age^3 - 0.0014*age^2 + 0.0163*age + 0.0492
plot(age,freq)
freq <- -8E-07*age^3 + 0.0002*age^2 - 0.0099*age + 0.2103
plot(age,freq)
freqH <- -4E-06*age^3 + 0.0005*age^2 - 0.0208*age + 0.3318
plot(age,freqH)
plot(age,freqF)
freqF <- -8E-07*age^3 + 0.0002*age^2 - 0.0099*age + 0.2103
rm(freq)
freqF,freqH
freqF;freqH
freqF-freqH
setwd("~/Documents/Biz/Insurance/Simulations/Données démographiques Québec")
d <- read.csv("Model.csv")
setwd("~/Documents/Biz/Insurance/Simulations/Données démographiques Québec")
library(tidyr)
library(plyr)
#Prompting the user for the size of the desired sample
size <- function(){
x <<- readline("What sample size? ")
as.numeric(x)
}
#Generating the random sample and storing it in object "samp"
sampler <- function(){
samp <<- sample(PopQc2013TM$ID,size(), prob=PopQc2013TM$Proportion,replace = TRUE)
}
dem <- read.csv("TablePopQc.csv", header=TRUE)
dem$X <- NULL
dem$X.1 <- NULL
tidyDem <- gather(dem, Age,n, X0:X90)
PopQc <- tidyDem[1:59056,]
rm(tidyDem)
PopQc$Age <- extract_numeric(PopQc$Age)
PopQc$n <- as.numeric(gsub(",","",PopQc$n))
PopQc2013 <- subset(PopQc, PopQc$Année == "2013p")
PopQc2013TM <- subset(PopQc2013, c(PopQc2013$Age>=16,PopQc2013$Age<=45))
#Because shit happened and 1564 NAs found their way to the bottom
PopQc2013TM <- PopQc2013TM[1:(4114-1564),]
PopQc2013TM$Proportion <- PopQc2013TM$n/sum(PopQc2013TM$n)
PopQc2013TM$ID <- 1:length(PopQc2013TM$Code)
row.names(PopQc2013TM) <- NULL
write.csv(PopQc2013TM, "Population Conducteurs Québec 2013.csv")
setwd("~/Documents/Biz/Insurance/Simulations/Données démographiques Québec")
library(tidyr)
library(plyr)
#Prompting the user for the size of the desired sample
size <- function(){
x <<- readline("What sample size? ")
as.numeric(x)
}
#Generating the random sample and storing it in object "samp"
sampler <- function(){
samp <<- sample(PopQc2013TM$ID,size(), prob=PopQc2013TM$Proportion,replace = TRUE)
}
dem <- read.csv("TablePopQc.csv", header=TRUE)
dem$X <- NULL
dem$X.1 <- NULL
tidyDem <- gather(dem, Age,n, X0:X90)
PopQc <- tidyDem[1:59056,]
rm(tidyDem)
PopQc$Age <- extract_numeric(PopQc$Age)
PopQc$n <- as.numeric(gsub(",","",PopQc$n))
PopQc2013 <- subset(PopQc, PopQc$Année == "2013")
PopQc2013TM <- subset(PopQc2013, c(PopQc2013$Age>=16,PopQc2013$Age<=45))
#Because shit happened and 1564 NAs found their way to the bottom
PopQc2013TM <- PopQc2013TM[1:(4114-1564),]
PopQc2013TM$Proportion <- PopQc2013TM$n/sum(PopQc2013TM$n)
PopQc2013TM$ID <- 1:length(PopQc2013TM$Code)
row.names(PopQc2013TM) <- NULL
write.csv(PopQc2013TM, "Population Conducteurs Québec 2013.csv")
PopQc2013 <- subset(PopQc, PopQc$Année == "2013")
PopQc2013 <- subset(PopQc, PopQc$Année == "2013")
View(PopQc)
PopQc2013 <- subset(PopQc, PopQc$Année == "2013r")
PopQc2013TM <- subset(PopQc2013, c(PopQc2013$Age>=16,PopQc2013$Age<=45))
#Because shit happened and 1564 NAs found their way to the bottom
PopQc2013TM <- PopQc2013TM[1:(4114-1564),]
PopQc2013TM$Proportion <- PopQc2013TM$n/sum(PopQc2013TM$n)
PopQc2013TM$ID <- 1:length(PopQc2013TM$Code)
row.names(PopQc2013TM) <- NULL
write.csv(PopQc2013TM, "Population Conducteurs Québec 2013.csv")
PopQc2013 <- subset(PopQc, PopQc$Année == "2013r")
PopQc2013TM <- subset(PopQc2013, c(PopQc2013$Age>=16,PopQc2013$Age<=45))
is.na(PopQc2013TM$Code)
sum(is.na(PopQc2013TM$Code))
PopQc2013TM <- PopQc2013TM[1:(4114-1564),]
View(PopQc2013TM)
?unzip
unzip("activity.csv")
data <- unzip("activity.csv",read.csv("activity.csv"))
data <- unzip("activity.csv",files=read.csv("activity.csv"))
data <- unzip("activity.zip",files=read.csv("activity.csv"))
setwd("~/GitHub/RepData_PeerAssessment1")
data <- unzip("activity.zip",files=read.csv("activity.csv"))
unzip("activity.zip")
data <- read.csv("activity.csv")
View(data)
View(data)
DayType <- data
DayType$days <- weekdays(DayType$date)
DayType$date
weekdays(DayType$date)
?weekdays
class(DayType$date)
DayType$days <- weekdays(as.Date(DayType$date))
class(DayType$date)
DayType$days <- weekdays(as.Date(DayType$date))
class(DayType$date)
DayType$date
class(DayType$days)
DayType$days
DayType <- data
DayType$days <- weekdays(as.Date(DayType$date))
DayType$daytype[DayType$days == "Monday" | DayType$days == "Tuesday" | DayType$days == "Wednesday" | DayType$days == "Thursday" | DayType$days == "Friday"] <- "Weekday"
DayType$daytype[DayType$days == "Saturday" | DayType$days == "Sunday"] <- "Weekend"
IntervalDay <- ddply(DayType,.(daytype,interval),summarize, MeanSteps = mean(steps,na.rm=TRUE))
qplot(interval,MeanSteps, data = IntervalDay, colour = days)
qplot(interval,MeanSteps, data = IntervalDay, colour = days, geom = "smooth", method="auto")
library(ggplot2)
DayType <- data
DayType$days <- weekdays(as.Date(DayType$date))
DayType$daytype[DayType$days == "Monday" | DayType$days == "Tuesday" | DayType$days == "Wednesday" | DayType$days == "Thursday" | DayType$days == "Friday"] <- "Weekday"
DayType$daytype[DayType$days == "Saturday" | DayType$days == "Sunday"] <- "Weekend"
IntervalDay <- ddply(DayType,.(daytype,interval),summarize, MeanSteps = mean(steps,na.rm=TRUE))
qplot(interval,MeanSteps, data = IntervalDay, colour = days)
qplot(interval,MeanSteps, data = IntervalDay, colour = days, geom = "smooth", method="auto")
setwd("~/GitHub/RepData_PeerAssessment1")
unzip("activity.zip")
data <- read.csv("activity.csv")
data$date <- as.Date(data$date)
View(data)
class(data$date)
total <- ddply(data,"date",summarize, sum = sum(steps))
plot(total$date,total$sum, type="h")
#average
mean(total$sum,na.rm=TRUE)
#median
median(total$sum,na.rm=TRUE)
inter <- ddply(data,"interval",summarize, TotalSteps = sum(steps,na.rm=TRUE))
plot(inter$interval,inter$TotalSteps, type="l")
TotalNAs <- sum(is.na(data))
# 2. Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
boom <- ddply(data, .(interval), transform, steps=ifelse(is.na(steps), median(steps, na.rm=TRUE), steps))
blah <- ddply(boom,"date",summarize, sum = sum(steps))
plot(blah$date,blah$sum, type="h")
#average
mean(blah$sum,na.rm=TRUE)
#median
median(blah$sum,na.rm=TRUE)
TotalNAs <- sum(is.na(data))
TotalNAs
# 1. Report total number of NAs
sum(is.na(data))
# 2. Devise a strategy for filling in all of the missing values in the dataset. The strategy does not need to be sophisticated. For example, you could use the mean/median for that day, or the mean for that 5-minute interval, etc.
boom <- ddply(data, .(interval), transform, steps=ifelse(is.na(steps), median(steps, na.rm=TRUE), steps))
blah <- ddply(boom,"date",summarize, sum = sum(steps))
plot(blah$date,blah$sum, type="h")
#average
mean(blah$sum,na.rm=TRUE)
#median
median(blah$sum,na.rm=TRUE)
DayType <- data
DayType$days <- weekdays(as.Date(DayType$date))
DayType$daytype[DayType$days == "Monday" | DayType$days == "Tuesday" | DayType$days == "Wednesday" | DayType$days == "Thursday" | DayType$days == "Friday"] <- "Weekday"
DayType$daytype[DayType$days == "Saturday" | DayType$days == "Sunday"] <- "Weekend"
IntervalDay <- ddply(DayType,.(daytype,interval),summarize, MeanSteps = mean(steps,na.rm=TRUE))
IntervalDay
qplot(interval,MeanSteps, data = IntervalDay, colour = days)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "smooth", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(MeanSteps, data = IntervalDay, colour = daytype, geom = "density", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "line", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "ribbon", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "area", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "dotplot", method="auto")
rm(TotalNAs)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "quantile", method="auto")
install.packages("quantreg")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "quantile", method="auto")
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype)
qplot(interval,MeanSteps, data = IntervalDay, colour = daytype, geom = "quantile")
